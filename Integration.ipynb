{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0db645aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'tensorflowjs_converter' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!mkdir model\n",
    "!tensorflowjs_converter --input_format keras \"Eye Drowsiness Only Eyes RGB Extra Dataset\" model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4389646f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflowjs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9462f84cb5cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflowjs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfjs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtfjs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_keras_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tfjsmodel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflowjs'"
     ]
    }
   ],
   "source": [
    "import tensorflowjs as tfjs\n",
    "tfjs.converters.save_keras_model(model, \"tfjsmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca84755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3dc14408",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [\"Fold3_part1_26_0\", \"Fold3_part1_27_0\", \"Fold3_part1_26_5\", \"Fold3_part1_26_10\", \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1bac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"Eye Drowsiness Only Eyes RGB Extra Dataset\")\n",
    "#model1 = load_model(\"./Eye Drowsiness RGB\")\n",
    "#model2 = load_model(\"./Eye Drowsiness Detection\")\n",
    "#model3 = load_model(\"./Eye Drowsiness Only Eyes RGB\")\n",
    "#model4 = load_model(\"./Eye Drowsiness Only Eyes GS\")\n",
    "model5 = load_model(\"./Eye Drowsiness Only Eyes RGB 2\")\n",
    "model6 = load_model(\"./Eye Drowsiness Only Eyes RGB Cleaned\")\n",
    "model7 = load_model(\"./Eye Drowsiness Only Eyes RGB Dataset Enhanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df41434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictOnlyEyesFromEyes:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.frame = None\n",
    "        \n",
    "    def set_frame(self, frame):\n",
    "        self.frame = frame\n",
    "            \n",
    "    def predict_frame(self):\n",
    "        frame = cv2.imread(self.path)\n",
    "        frame = cv2.resize(frame, (85, 40))\n",
    "        \n",
    "        self.set_frame(frame)\n",
    "        \n",
    "        X_query = np.array([frame])\n",
    "        X_query = tf.convert_to_tensor(X_query)\n",
    "        pred = model6.predict([X_query])\n",
    "    \n",
    "        return pred\n",
    "    \n",
    "    def inference(self):\n",
    "        pred = self.predict_frame()\n",
    "                \n",
    "        alert = pred[0][0]\n",
    "        drowsy = pred[0][1]\n",
    "        \n",
    "        if (alert > drowsy):\n",
    "            return [\"Alert\", alert, drowsy, self.frame]\n",
    "        elif (alert < drowsy):\n",
    "            return [\"Drowsy\", alert, drowsy, self.frame]\n",
    "        else:\n",
    "            return [\"None\", alert, drowsy, self.frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeac7e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"D:\\Driver Drowsiness\\Dataset\\Fold3_part1_26_5\\Frames\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "300137d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/626\n",
      "2/626\n",
      "3/626\n",
      "4/626\n",
      "5/626\n",
      "6/626\n",
      "7/626\n",
      "8/626\n",
      "9/626\n",
      "10/626\n",
      "11/626\n",
      "12/626\n",
      "13/626\n",
      "14/626\n",
      "15/626\n",
      "16/626\n",
      "17/626\n",
      "18/626\n",
      "19/626\n",
      "20/626\n",
      "21/626\n",
      "22/626\n",
      "23/626\n",
      "24/626\n",
      "25/626\n",
      "26/626\n",
      "27/626\n",
      "28/626\n",
      "29/626\n",
      "30/626\n",
      "31/626\n",
      "32/626\n",
      "33/626\n",
      "34/626\n",
      "35/626\n",
      "36/626\n",
      "37/626\n",
      "38/626\n",
      "39/626\n",
      "40/626\n",
      "41/626\n",
      "42/626\n",
      "43/626\n",
      "44/626\n",
      "45/626\n",
      "46/626\n",
      "47/626\n",
      "48/626\n",
      "49/626\n",
      "Error Encountered!!\n",
      "local variable 'mesh_points' referenced before assignment\n",
      "50/626\n",
      "51/626\n",
      "52/626\n",
      "53/626\n",
      "54/626\n",
      "55/626\n",
      "56/626\n",
      "57/626\n",
      "58/626\n",
      "59/626\n",
      "60/626\n",
      "61/626\n",
      "62/626\n",
      "63/626\n",
      "64/626\n",
      "65/626\n",
      "66/626\n",
      "67/626\n",
      "68/626\n",
      "69/626\n",
      "70/626\n",
      "71/626\n",
      "72/626\n",
      "73/626\n",
      "74/626\n",
      "75/626\n",
      "76/626\n",
      "77/626\n",
      "78/626\n",
      "79/626\n",
      "80/626\n",
      "81/626\n",
      "82/626\n",
      "83/626\n",
      "84/626\n",
      "85/626\n",
      "86/626\n",
      "87/626\n",
      "88/626\n",
      "89/626\n",
      "90/626\n",
      "91/626\n",
      "92/626\n",
      "93/626\n",
      "94/626\n",
      "95/626\n",
      "96/626\n",
      "97/626\n",
      "98/626\n",
      "99/626\n",
      "100/626\n",
      "101/626\n",
      "102/626\n",
      "103/626\n",
      "104/626\n",
      "105/626\n",
      "106/626\n",
      "107/626\n",
      "108/626\n",
      "109/626\n",
      "110/626\n",
      "111/626\n",
      "112/626\n",
      "113/626\n",
      "114/626\n",
      "115/626\n",
      "116/626\n",
      "117/626\n",
      "118/626\n",
      "119/626\n",
      "120/626\n",
      "121/626\n",
      "122/626\n",
      "123/626\n",
      "124/626\n",
      "125/626\n",
      "126/626\n",
      "127/626\n",
      "128/626\n",
      "129/626\n",
      "130/626\n",
      "131/626\n",
      "132/626\n",
      "133/626\n",
      "134/626\n",
      "135/626\n",
      "136/626\n",
      "137/626\n",
      "138/626\n",
      "139/626\n",
      "140/626\n",
      "141/626\n",
      "142/626\n",
      "143/626\n",
      "144/626\n",
      "145/626\n",
      "146/626\n",
      "147/626\n",
      "148/626\n",
      "149/626\n",
      "150/626\n",
      "151/626\n",
      "152/626\n",
      "153/626\n",
      "154/626\n",
      "155/626\n",
      "156/626\n",
      "157/626\n",
      "158/626\n",
      "159/626\n",
      "160/626\n",
      "161/626\n",
      "162/626\n",
      "163/626\n",
      "164/626\n",
      "165/626\n",
      "166/626\n",
      "167/626\n",
      "168/626\n",
      "169/626\n",
      "170/626\n",
      "171/626\n",
      "172/626\n",
      "173/626\n",
      "174/626\n",
      "175/626\n",
      "176/626\n",
      "177/626\n",
      "178/626\n",
      "179/626\n",
      "180/626\n",
      "181/626\n",
      "182/626\n",
      "183/626\n",
      "184/626\n",
      "185/626\n",
      "186/626\n",
      "187/626\n",
      "188/626\n",
      "189/626\n",
      "190/626\n",
      "191/626\n",
      "192/626\n",
      "193/626\n",
      "194/626\n",
      "195/626\n",
      "196/626\n",
      "197/626\n",
      "198/626\n",
      "199/626\n",
      "200/626\n",
      "201/626\n",
      "202/626\n",
      "203/626\n",
      "204/626\n",
      "205/626\n",
      "206/626\n",
      "207/626\n",
      "208/626\n",
      "209/626\n",
      "210/626\n",
      "211/626\n",
      "212/626\n",
      "213/626\n",
      "214/626\n",
      "215/626\n",
      "216/626\n",
      "217/626\n",
      "218/626\n",
      "219/626\n",
      "220/626\n",
      "221/626\n",
      "222/626\n",
      "223/626\n",
      "224/626\n",
      "225/626\n",
      "226/626\n",
      "227/626\n",
      "228/626\n",
      "229/626\n",
      "230/626\n",
      "231/626\n",
      "232/626\n",
      "233/626\n",
      "234/626\n",
      "235/626\n",
      "236/626\n",
      "237/626\n",
      "238/626\n",
      "239/626\n",
      "240/626\n",
      "241/626\n",
      "242/626\n",
      "243/626\n",
      "244/626\n",
      "245/626\n",
      "246/626\n",
      "247/626\n",
      "248/626\n",
      "249/626\n",
      "250/626\n",
      "251/626\n",
      "252/626\n",
      "253/626\n",
      "254/626\n",
      "255/626\n",
      "256/626\n",
      "257/626\n",
      "258/626\n",
      "259/626\n",
      "260/626\n",
      "261/626\n",
      "262/626\n",
      "263/626\n",
      "264/626\n",
      "265/626\n",
      "266/626\n",
      "267/626\n",
      "268/626\n",
      "269/626\n",
      "270/626\n",
      "271/626\n",
      "272/626\n",
      "273/626\n",
      "274/626\n",
      "275/626\n",
      "276/626\n",
      "277/626\n",
      "278/626\n",
      "279/626\n",
      "280/626\n",
      "281/626\n",
      "282/626\n",
      "283/626\n",
      "284/626\n",
      "285/626\n",
      "286/626\n",
      "287/626\n",
      "288/626\n",
      "289/626\n",
      "290/626\n",
      "291/626\n",
      "292/626\n",
      "293/626\n",
      "294/626\n",
      "295/626\n",
      "296/626\n",
      "297/626\n",
      "298/626\n",
      "299/626\n",
      "300/626\n",
      "301/626\n",
      "302/626\n",
      "303/626\n",
      "304/626\n",
      "305/626\n",
      "306/626\n",
      "307/626\n",
      "308/626\n",
      "309/626\n",
      "310/626\n",
      "311/626\n",
      "312/626\n",
      "313/626\n",
      "314/626\n",
      "315/626\n",
      "316/626\n",
      "317/626\n",
      "318/626\n",
      "319/626\n",
      "320/626\n",
      "321/626\n",
      "322/626\n",
      "323/626\n",
      "324/626\n",
      "325/626\n",
      "326/626\n",
      "327/626\n",
      "328/626\n",
      "329/626\n",
      "330/626\n",
      "331/626\n",
      "332/626\n",
      "333/626\n",
      "334/626\n",
      "335/626\n",
      "336/626\n",
      "337/626\n",
      "338/626\n",
      "339/626\n",
      "340/626\n",
      "341/626\n",
      "342/626\n",
      "343/626\n",
      "344/626\n",
      "345/626\n",
      "346/626\n",
      "347/626\n",
      "348/626\n",
      "349/626\n",
      "350/626\n",
      "351/626\n",
      "352/626\n",
      "353/626\n",
      "354/626\n",
      "355/626\n",
      "356/626\n",
      "357/626\n",
      "358/626\n",
      "359/626\n",
      "360/626\n",
      "361/626\n",
      "362/626\n",
      "363/626\n",
      "364/626\n",
      "365/626\n",
      "366/626\n",
      "367/626\n",
      "368/626\n",
      "369/626\n",
      "370/626\n",
      "371/626\n",
      "372/626\n",
      "373/626\n",
      "374/626\n",
      "375/626\n",
      "376/626\n",
      "377/626\n",
      "378/626\n",
      "379/626\n",
      "380/626\n",
      "381/626\n",
      "382/626\n",
      "383/626\n",
      "384/626\n",
      "385/626\n",
      "386/626\n",
      "387/626\n",
      "388/626\n",
      "389/626\n",
      "390/626\n",
      "391/626\n",
      "392/626\n",
      "393/626\n",
      "394/626\n",
      "395/626\n",
      "396/626\n",
      "397/626\n",
      "398/626\n",
      "399/626\n",
      "400/626\n",
      "401/626\n",
      "402/626\n",
      "403/626\n",
      "404/626\n",
      "405/626\n",
      "406/626\n",
      "407/626\n",
      "408/626\n",
      "409/626\n",
      "410/626\n",
      "411/626\n",
      "412/626\n",
      "413/626\n",
      "414/626\n",
      "415/626\n",
      "416/626\n",
      "417/626\n",
      "418/626\n",
      "419/626\n",
      "420/626\n",
      "421/626\n",
      "422/626\n",
      "423/626\n",
      "424/626\n",
      "425/626\n",
      "426/626\n",
      "427/626\n",
      "428/626\n",
      "429/626\n",
      "430/626\n",
      "431/626\n",
      "432/626\n",
      "433/626\n",
      "434/626\n",
      "435/626\n",
      "436/626\n",
      "437/626\n",
      "438/626\n",
      "439/626\n",
      "440/626\n",
      "441/626\n",
      "442/626\n",
      "443/626\n",
      "444/626\n",
      "445/626\n",
      "446/626\n",
      "447/626\n",
      "448/626\n",
      "449/626\n",
      "450/626\n",
      "451/626\n",
      "452/626\n",
      "453/626\n",
      "454/626\n",
      "455/626\n",
      "456/626\n",
      "457/626\n",
      "458/626\n",
      "459/626\n",
      "460/626\n",
      "461/626\n",
      "462/626\n",
      "463/626\n",
      "464/626\n",
      "465/626\n",
      "466/626\n",
      "467/626\n",
      "468/626\n",
      "469/626\n",
      "470/626\n",
      "471/626\n",
      "472/626\n",
      "473/626\n",
      "474/626\n",
      "475/626\n",
      "476/626\n",
      "477/626\n",
      "478/626\n",
      "479/626\n",
      "480/626\n",
      "481/626\n",
      "482/626\n",
      "483/626\n",
      "484/626\n",
      "485/626\n",
      "486/626\n",
      "487/626\n",
      "488/626\n",
      "489/626\n",
      "490/626\n",
      "491/626\n",
      "492/626\n",
      "493/626\n",
      "494/626\n",
      "495/626\n",
      "496/626\n",
      "497/626\n",
      "498/626\n",
      "499/626\n",
      "500/626\n",
      "501/626\n",
      "502/626\n",
      "503/626\n",
      "504/626\n",
      "505/626\n",
      "506/626\n",
      "507/626\n",
      "508/626\n",
      "509/626\n",
      "510/626\n",
      "511/626\n",
      "512/626\n",
      "513/626\n",
      "514/626\n",
      "515/626\n",
      "516/626\n",
      "517/626\n",
      "518/626\n",
      "519/626\n",
      "520/626\n",
      "521/626\n",
      "522/626\n",
      "523/626\n",
      "524/626\n",
      "525/626\n",
      "526/626\n",
      "527/626\n",
      "528/626\n",
      "529/626\n",
      "530/626\n",
      "531/626\n",
      "532/626\n",
      "533/626\n",
      "534/626\n",
      "535/626\n",
      "536/626\n",
      "537/626\n",
      "538/626\n",
      "539/626\n",
      "540/626\n",
      "541/626\n",
      "542/626\n",
      "543/626\n",
      "544/626\n",
      "545/626\n",
      "546/626\n",
      "547/626\n",
      "548/626\n",
      "549/626\n",
      "550/626\n",
      "551/626\n",
      "552/626\n",
      "553/626\n",
      "554/626\n",
      "555/626\n",
      "556/626\n",
      "557/626\n",
      "558/626\n",
      "559/626\n",
      "560/626\n",
      "561/626\n",
      "562/626\n",
      "563/626\n",
      "564/626\n",
      "565/626\n",
      "566/626\n",
      "567/626\n",
      "568/626\n",
      "569/626\n",
      "570/626\n",
      "571/626\n",
      "572/626\n",
      "573/626\n",
      "574/626\n",
      "575/626\n",
      "576/626\n",
      "577/626\n",
      "578/626\n",
      "579/626\n",
      "580/626\n",
      "581/626\n",
      "582/626\n",
      "583/626\n",
      "584/626\n",
      "585/626\n",
      "586/626\n",
      "587/626\n",
      "588/626\n",
      "589/626\n",
      "590/626\n",
      "591/626\n",
      "592/626\n",
      "593/626\n",
      "594/626\n",
      "595/626\n",
      "596/626\n",
      "597/626\n",
      "598/626\n",
      "599/626\n",
      "600/626\n",
      "601/626\n",
      "602/626\n",
      "603/626\n",
      "604/626\n",
      "605/626\n",
      "606/626\n",
      "607/626\n",
      "608/626\n",
      "609/626\n",
      "610/626\n",
      "611/626\n",
      "612/626\n",
      "613/626\n",
      "614/626\n",
      "615/626\n",
      "616/626\n",
      "617/626\n",
      "618/626\n",
      "619/626\n",
      "620/626\n",
      "621/626\n",
      "622/626\n",
      "623/626\n",
      "624/626\n",
      "625/626\n",
      "626/626\n"
     ]
    }
   ],
   "source": [
    "path = \"../Dataset/Fold3_part1_27_5/Frames\"\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    i_index = os.listdir(path).index(i)\n",
    "    print(str(i_index + 1) + \"/\" + str(len(os.listdir(path))))\n",
    "    \n",
    "    predict = PredictOnlyEyes(os.path.join(path, i))\n",
    "    try:\n",
    "        pred = predict.inference()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue  \n",
    "        \n",
    "    if pred == \"Alert\":\n",
    "        shutil.copy(os.path.join(path, i), \"../Dataset/Fold3_part1_27_5/Alert\")\n",
    "        continue\n",
    "    if pred == \"Drowsy\":\n",
    "        shutil.copy(os.path.join(path, i), \"../Dataset/Fold3_part1_27_5/Drowsy\")\n",
    "        continue\n",
    "  \n",
    "    shutil.copy(os.path.join(path, i), \"../Dataset/Fold3_part1_27_5/None\")\n",
    "    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c3c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictOnlyEyes:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.croppedL = None\n",
    "        self.croppedR = None\n",
    "    \n",
    "    def set_cropped(self, frameL, frameR):\n",
    "        self.croppedL = frameL\n",
    "        self.croppedR = frameR\n",
    "    \n",
    "    def mediapipe(self):\n",
    "        with mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.6, min_tracking_confidence=0.6) as face_mesh:\n",
    "            frame = cv2.imread(self.path)\n",
    "            print(frame.shape)\n",
    "            results = face_mesh.process(frame)\n",
    "        \n",
    "            img_h, img_w = frame.shape[:2]\n",
    "            \n",
    "            try:\n",
    "                mesh_points=np.array([np.multiply([p.x, p.y], [img_w, img_h]).astype(int) for p in results.multi_face_landmarks[0].landmark])\n",
    "            except Exception as e:\n",
    "                print(\"Error Encountered!!\")\n",
    "                \n",
    "            xTL, yTL = mesh_points[27] # Top\n",
    "            xLL, yLL = mesh_points[130] # Left\n",
    "            xBL, yBL = mesh_points[23] # Bottom\n",
    "            xRL, yRL = mesh_points[244] # Right\n",
    "\n",
    "            xTR, yTR = mesh_points[257] # Top\n",
    "            xLR, yLR = mesh_points[464] # Left\n",
    "            xBR, yBR = mesh_points[253] # Bottom\n",
    "            xRR, yRR = mesh_points[359] # Right\n",
    "            \n",
    "            rightFrame = frame[yTR - 5:yBR + 5, xLR - 5:xRR + 5]\n",
    "            leftFrame = frame[yTL - 5:yBL + 5, xLL - 5:xRL + 5]\n",
    "\n",
    "            self.set_cropped(leftFrame, rightFrame)\n",
    "            \n",
    "    def predict_frame(self):\n",
    "        frameL = cv2.resize(self.croppedL, (85, 40))\n",
    "        frameR = cv2.resize(self.croppedR, (85, 40))\n",
    "        \n",
    "       # frameL = cv2.cvtColor(frameL, cv2.COLOR_RGB2GRAY)\n",
    "        #frameR = cv2.cvtColor(frameR, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        \n",
    "        X_queryL = np.array([frameL])\n",
    "        X_queryL = tf.convert_to_tensor(X_queryL)\n",
    "        predL = model.predict([X_queryL])\n",
    "        \n",
    "        X_queryR = np.array([frameR])\n",
    "        X_queryR = tf.convert_to_tensor(X_queryR)\n",
    "        predR = model.predict([X_queryR])\n",
    "        \n",
    "        return [predL, predR]\n",
    "    \n",
    "    def inference(self):\n",
    "        self.mediapipe()\n",
    "        pred = self.predict_frame()\n",
    "        \n",
    "        predL, predR = pred       \n",
    "        \n",
    "#         print(predL, predR)\n",
    "        \n",
    "        alertL = predL[0][0]\n",
    "        drowsyL = predL[0][1]\n",
    "        \n",
    "        alertR = predR[0][0]\n",
    "        drowsyR = predR[0][1]\n",
    "    \n",
    "#         cv2.imshow(\"as\", self.croppedL)\n",
    "#         cv2.waitKey(0)\n",
    "\n",
    "#         cv2.imshow(\"as\", self.croppedR)\n",
    "#         cv2.waitKey(0)\n",
    "\n",
    "        #return pred\n",
    "       \n",
    "        if (alertR > drowsyR) and (alertL > drowsyL):\n",
    "            return \"Alert\"\n",
    "        if (alertR < drowsyR) and (alertL < drowsyL):\n",
    "            return \"Drowsy\"\n",
    "        \n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f30aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 1080, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Drowsy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = \"../Dataset/Fold4_part1_38_0/Drowsy/7230.jpg\"\n",
    "predict = PredictOnlyEyes(test_path)\n",
    "predict.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5364df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/173\n",
      "1/173\n",
      "2/173\n",
      "3/173\n",
      "4/173\n",
      "5/173\n",
      "6/173\n",
      "7/173\n",
      "8/173\n",
      "9/173\n",
      "10/173\n",
      "11/173\n",
      "12/173\n",
      "13/173\n",
      "14/173\n",
      "15/173\n",
      "16/173\n",
      "17/173\n",
      "18/173\n",
      "19/173\n",
      "20/173\n",
      "21/173\n",
      "22/173\n",
      "23/173\n",
      "24/173\n",
      "25/173\n",
      "26/173\n",
      "27/173\n",
      "28/173\n",
      "29/173\n",
      "30/173\n",
      "31/173\n",
      "32/173\n",
      "33/173\n",
      "34/173\n",
      "35/173\n",
      "36/173\n",
      "37/173\n",
      "38/173\n",
      "39/173\n",
      "40/173\n",
      "41/173\n",
      "42/173\n",
      "43/173\n",
      "44/173\n",
      "45/173\n",
      "46/173\n",
      "47/173\n",
      "48/173\n",
      "49/173\n",
      "50/173\n",
      "51/173\n",
      "52/173\n",
      "53/173\n",
      "54/173\n",
      "55/173\n",
      "56/173\n",
      "57/173\n",
      "58/173\n",
      "59/173\n",
      "60/173\n",
      "61/173\n",
      "62/173\n",
      "63/173\n",
      "64/173\n",
      "65/173\n",
      "66/173\n",
      "67/173\n",
      "68/173\n",
      "69/173\n",
      "70/173\n",
      "71/173\n",
      "72/173\n",
      "73/173\n",
      "74/173\n",
      "75/173\n",
      "76/173\n",
      "77/173\n",
      "78/173\n",
      "79/173\n",
      "80/173\n",
      "81/173\n",
      "82/173\n",
      "83/173\n",
      "84/173\n",
      "85/173\n",
      "86/173\n",
      "87/173\n",
      "88/173\n",
      "89/173\n",
      "90/173\n",
      "91/173\n",
      "92/173\n",
      "93/173\n",
      "94/173\n",
      "95/173\n",
      "96/173\n",
      "97/173\n",
      "98/173\n",
      "99/173\n",
      "100/173\n",
      "101/173\n",
      "102/173\n",
      "103/173\n",
      "104/173\n",
      "105/173\n",
      "106/173\n",
      "107/173\n",
      "108/173\n",
      "109/173\n",
      "110/173\n",
      "111/173\n",
      "112/173\n",
      "113/173\n",
      "114/173\n",
      "115/173\n",
      "116/173\n",
      "117/173\n",
      "118/173\n",
      "119/173\n",
      "120/173\n",
      "121/173\n",
      "122/173\n",
      "123/173\n",
      "124/173\n",
      "125/173\n",
      "126/173\n",
      "127/173\n",
      "128/173\n",
      "129/173\n",
      "130/173\n",
      "131/173\n",
      "132/173\n",
      "133/173\n",
      "134/173\n",
      "135/173\n",
      "136/173\n",
      "137/173\n",
      "138/173\n",
      "139/173\n",
      "140/173\n",
      "141/173\n",
      "142/173\n",
      "143/173\n",
      "144/173\n",
      "145/173\n",
      "146/173\n",
      "147/173\n",
      "148/173\n",
      "149/173\n",
      "150/173\n",
      "151/173\n",
      "152/173\n",
      "153/173\n",
      "154/173\n",
      "155/173\n",
      "156/173\n",
      "157/173\n",
      "158/173\n",
      "159/173\n",
      "160/173\n",
      "161/173\n",
      "162/173\n",
      "163/173\n",
      "164/173\n",
      "165/173\n",
      "166/173\n",
      "167/173\n",
      "168/173\n",
      "169/173\n",
      "170/173\n",
      "171/173\n",
      "172/173\n"
     ]
    }
   ],
   "source": [
    "path = \"../Dataset/Fold4_part1_39_0/Frames\"\n",
    "dict_ = {}\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    i_index = os.listdir(path).index(i)\n",
    "    \n",
    "    print(str(i_index) + \"/\" + str(len(os.listdir(path))))\n",
    "    \n",
    "    predict = PredictOnlyEyes(os.path.join(path, i))\n",
    "    try:\n",
    "        pred = predict.inference()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"hehehe caught it!!!\")\n",
    "        continue\n",
    "        \n",
    "    if pred == \"Alert\":\n",
    "        shutil.copy(os.path.join(path, i), \"../Dataset/Fold4_part1_39_0/Alert\")\n",
    "    elif pred == \"Drowsy\":\n",
    "        shutil.copy(os.path.join(path, i), \"../Dataset/Fold4_part1_39_0/Drowsy\")   \n",
    "    else:\n",
    "        continue\n",
    "        #shutil.copy(os.path.join(path, i), \"../Dataset/Model Only Eyes Results/No Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d33019",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictTest:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.cropped = None\n",
    "    \n",
    "    def set_cropped(self, frame):\n",
    "        self.cropped = frame\n",
    "    \n",
    "    def mediapipe(self):\n",
    "        with mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.6, min_tracking_confidence=0.6) as face_mesh:\n",
    "            frame = cv2.imread(self.path)\n",
    "            results = face_mesh.process(frame)\n",
    "            \n",
    "            img_h, img_w = frame.shape[:2]\n",
    "            \n",
    "            try:\n",
    "                mesh_points=np.array([np.multiply([p.x, p.y], [img_w, img_h]).astype(int) for p in results.multi_face_landmarks[0].landmark])\n",
    "            except Exception as e:\n",
    "                print(\"Error Encountered!!\")\n",
    "                \n",
    "            top = mesh_points[68][1]\n",
    "            left = mesh_points[68][0]\n",
    "            right = mesh_points[447][0]\n",
    "            bottom = mesh_points[447][1]\n",
    "\n",
    "            frame_cropped = frame[top:bottom, left:right]\n",
    "            self.set_cropped(frame_cropped)\n",
    "            \n",
    "    def predict_frame(self):\n",
    "        #frame = cv2.cvtColor(self.cropped, cv2.COLOR_BGR2GRAY)\n",
    "        frame = cv2.imread(self.path)\n",
    "        frame = cv2.resize(frame, (250, 100))\n",
    "        X_query = np.array([frame])\n",
    "        X_query = tf.convert_to_tensor(X_query)\n",
    "        pred = model.predict([X_query])\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def inference(self):\n",
    "        #self.mediapipe()\n",
    "        pred = self.predict_frame()\n",
    "        \n",
    "        alert = pred[0][0]\n",
    "        drowsy = pred[0][1]\n",
    "        \n",
    "        #cv2.imshow(\"frame\", self.cropped)\n",
    "        #cv2.waitKey(0)\n",
    "        \n",
    "        \"\"\"\n",
    "        if alert > drowsy:\n",
    "            print(\"Alert hai!\")\n",
    "        else:\n",
    "            print(\"Drowsy hai!\")\n",
    "        \"\"\"\n",
    "            \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predict:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.cropped = None\n",
    "    \n",
    "    def set_cropped(self, frame):\n",
    "        self.cropped = frame\n",
    "    \n",
    "    def mediapipe(self):\n",
    "        with mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.6, min_tracking_confidence=0.6) as face_mesh:\n",
    "            frame = cv2.imread(self.path)\n",
    "            results = face_mesh.process(frame)\n",
    "            \n",
    "            img_h, img_w = frame.shape[:2]\n",
    "            \n",
    "            try:\n",
    "                mesh_points=np.array([np.multiply([p.x, p.y], [img_w, img_h]).astype(int) for p in results.multi_face_landmarks[0].landmark])\n",
    "            except Exception as e:\n",
    "                print(\"Error Encountered!!\")\n",
    "                \n",
    "            top = mesh_points[68][1]\n",
    "            left = mesh_points[68][0]\n",
    "            right = mesh_points[447][0]\n",
    "            bottom = mesh_points[447][1]\n",
    "\n",
    "            frame_cropped = frame[top:bottom, left:right]\n",
    "            self.set_cropped(frame_cropped)\n",
    "            \n",
    "    def predict_frame(self):\n",
    "        #frame = cv2.cvtColor(self.cropped, cv2.COLOR_BGR2GRAY)\n",
    "        frame = cv2.resize(self.cropped, (250, 100))\n",
    "        X_query = np.array([frame])\n",
    "        X_query = tf.convert_to_tensor(X_query)\n",
    "        pred = model.predict([X_query])\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def inference(self):\n",
    "        self.mediapipe()\n",
    "        pred = self.predict_frame()\n",
    "        \n",
    "        alert = pred[0][0]\n",
    "        drowsy = pred[0][1]\n",
    "        \n",
    "        cv2.imshow(\"frame\", self.cropped)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        \"\"\"\n",
    "        if alert > drowsy:\n",
    "            print(\"Alert hai!\")\n",
    "        else:\n",
    "            print(\"Drowsy hai!\")\n",
    "        \"\"\"\n",
    "            \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e47ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"D:\\Driver Drowsiness\\Dataset\\Model RGB 2 Results\\Drowsy\\4554_alert.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89628976",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = Predict(\"../Dataset/Model RGB 2 Results/Drowsy/3343_alert.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3981ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ff7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicttest = PredictTest(\"../Dataset/Test Model RGB 2/3343_alert.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dc70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicttest.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55a8f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"../Dataset/Eye Dataset/Drowsy Raw\"\n",
    "dict_ = {}\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    i_index = os.listdir(path).index(i)\n",
    "    \n",
    "    print(str(i_index) + \"/\" + str(len(os.listdir(path))))\n",
    "    \n",
    "    predict = Predict(os.path.join(path, i))iiii\n",
    "    try:\n",
    "        pred = predict.inference()\n",
    "    except:\n",
    "        print(\"hehehe caught it!!!\")\n",
    "        continue\n",
    "    \n",
    "    alert = pred[0][0]\n",
    "    drowsy = pred[0][1]\n",
    "    \n",
    "    prediction = \"\"\n",
    "    \n",
    "    if alert > 0.7:\n",
    "        dict_[i] = \"Alert\"\n",
    "        shutil.copy(os.path.join(path, i), \"../Dataset/Model RGB 2 Results/Alert\")\n",
    "        continue\n",
    "    elif drowsy > 0.7:\n",
    "        dict_[i] = \"Drowsy\"\n",
    "        shutil.copy(os.path.join(path, i), \"../Dataset/Model RGB 2 Results/Drowsy\")\n",
    "        continue\n",
    "    else:\n",
    "        dict_[i] = \"No prediction\"\n",
    "        shutil.copy(os.path.join(path, i), \"../Dataset/Model RGB 2 Results/No Prediction\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6732e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alert = 0\n",
    "drowsy = 0\n",
    "np_ = 0\n",
    "\n",
    "for i in dict_.keys():\n",
    "    if dict_[i] == \"Alert\":\n",
    "        alert+= 1\n",
    "    if dict_[i] == \"Drowsy\":\n",
    "        drowsy +=1\n",
    "    if dict_[i] == \"No prediction\":\n",
    "        np_ += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1fd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "drowsy, alert, np_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b06958",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0849c865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
